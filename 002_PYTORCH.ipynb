{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "002_PYTORCH.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZOL14srGUyGG",
        "colab_type": "text"
      },
      "source": [
        "This notebook builds on top of the first block, covering basic concepts useful to understand the PyTorch deep learning framework such as **objective function**, **non-linearities**, **affine maps**, etc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DzycKauucDXz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbVlNGLrcDu6",
        "colab_type": "code",
        "outputId": "be65b3d3-066c-49c6-e012-a560585a7e44",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "# check if cuda is available in your computer\n",
        "print(\"---------------------------------------------------\")\n",
        "print(\"Cuda status:\", torch.cuda.is_available())\n",
        "\n",
        "device_0 = torch.device(\"cuda\")\n",
        "device_1 = torch.device(\"cpu\")\n",
        "\n",
        "print(\"---------------------------------------------------\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "---------------------------------------------------\n",
            "Cuda status: True\n",
            "---------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_2REfm8Eah7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "A = torch.tensor([1, 2, 3 ,4])\n",
        "B = torch.tensor([1, 2, 3 ,4]).cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBrG-H6dEmMp",
        "colab_type": "code",
        "outputId": "19ef60a5-ac44-4d81-aa2b-b50b59c8e0eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "A.device"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QcYZF8h8EmWf",
        "colab_type": "code",
        "outputId": "d4945e0c-7dd7-4e7b-a766-b2f858551d42",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "B.device"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fqZBF2viEmZQ",
        "colab_type": "code",
        "outputId": "4483bee0-cf7e-4b72-c1d3-6504f8b1d32e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "A.is_cuda"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nk8xalurFNEc",
        "colab_type": "code",
        "outputId": "3de02845-95d4-40ac-f10d-5395f9b1c7ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "B.is_cuda"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W39NZ6lKFNHK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2C7F5Cz9FcS-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgYJzwCdFNWz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iqC0WlhkUyJX",
        "colab_type": "text"
      },
      "source": [
        "# **Computation Graph**\n",
        "A simplified definition of a neural network is a string of functions that are differentiable and that we can combine together to get more complicated functions. An intuitive way to express this process is through **computation graphs**. PyTorch provide efficient functionalities for **automatic differentiation**.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mRADIzeJbUWa",
        "colab_type": "text"
      },
      "source": [
        "https://towardsdatascience.com/the-2-step-guide-to-upload-images-in-google-colab-b51348e882e4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cFWq6kIYVwy5",
        "colab_type": "text"
      },
      "source": [
        "[link text](https://drive.google.com/file/d/1lqRo4lahewpAJddyE6Y0uPhxvgQBQF2k/view?usp=sharing)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "om7bE4umbL9C",
        "colab_type": "text"
      },
      "source": [
        "![222](https://drive.google.com/uc?id=1lqRo4lahewpAJddyE6Y0uPhxvgQBQF2k)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UoMtyrUOcBVI",
        "colab_type": "code",
        "outputId": "e6a721bd-130c-4b09-ebb9-1bbf5f22058f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "source": [
        "### FORWARD\n",
        "print(\"---------------------------------------------------\")\n",
        "print(\"FORWARD: \")\n",
        "\n",
        "# layer 1\n",
        "a = torch.tensor(2.0, requires_grad=True)\n",
        "b = torch.tensor(1.0, requires_grad=True)\n",
        "\n",
        "# layer 2\n",
        "c = a + b\n",
        "c.retain_grad()         # retrain gradients for non-leaf Tensors\n",
        "\n",
        "d = b + 1.0\n",
        "d.retain_grad()         # retrain gradients for non-leaf Tensors\n",
        "\n",
        "# layer 3\n",
        "e = c * d\n",
        "\n",
        "print(\"e: \", e)\n",
        "\n",
        "### BACKWARD\n",
        "print(\"---------------------------------------------------\")\n",
        "print(\"BACKWARD: \")\n",
        "\n",
        "e.backward()\n",
        "\n",
        "print(\"c.grad: \", c.grad.detach().item()) # de/dc\n",
        "print(\"d.grad: \", d.grad.detach().item()) # de/dd"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "---------------------------------------------------\n",
            "FORWARD: \n",
            "e:  tensor(6., grad_fn=<MulBackward0>)\n",
            "---------------------------------------------------\n",
            "BACKWARD: \n",
            "c.grad:  2.0\n",
            "d.grad:  3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imbdog4GG1E-",
        "colab_type": "text"
      },
      "source": [
        "https://towardsdatascience.com/getting-started-with-pytorch-part-1-understanding-how-automatic-differentiation-works-5008282073ec"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8AbEHx8G85Y",
        "colab_type": "text"
      },
      "source": [
        "Compute the derivates of a and b with respect to c. Just the left part of the figure above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h6R8PG-YFHXa",
        "colab_type": "code",
        "outputId": "b4a1bf2b-d052-47ea-fd4f-0eca8757657b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "# layer 1\n",
        "a = torch.tensor(2.0, requires_grad=True)\n",
        "b = torch.tensor(1.0, requires_grad=True)\n",
        "\n",
        "# layer 2\n",
        "c = a + b\n",
        "c.retain_grad() # retrain gradients for non-leaf Tensors\n",
        "\n",
        "print(\"---------------------------------------------------\")\n",
        "print(\"BACKWARD: \")\n",
        "\n",
        "c.backward()\n",
        "\n",
        "print(\"a.grad: \", a.grad.detach().item()) # dc/da\n",
        "print(\"b.grad: \", b.grad.detach().item()) # dc/db"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "---------------------------------------------------\n",
            "BACKWARD: \n",
            "a.grad:  1.0\n",
            "b.grad:  1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZS1Q95BHmO-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8XKxv8wMIEX3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NcBgnsEXIEo0",
        "colab_type": "text"
      },
      "source": [
        "# **Input**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0YfwMtzeILiJ",
        "colab_type": "text"
      },
      "source": [
        "The first component of the neural network is the **input**. Inputs have to be represented in tensor formats as this is the main data structure or representation used in PyTorch. We introduced tensors and a few operations that are possible with them in the previous segment of this tutorial. Therefore, we will briefly review different kinds of inputs that are common in **NLP**. This is the first actual part of the tutorial where we start to introduce concepts related to NLP and how we will integrate them with the other components provided in the PyTorch ecosystem. Inputs can be represented in either scalars, vectors, or multi-dimensional matrices. Whichever the type, they are all represented as tensors in PyTorch. Typically, the inputs are composed from publicly available datasets.\n",
        "\n",
        "Inputs to an NLP deep learning model are usually of the following dimensions: _{batch_size * max_sequence_length * vocab_size}_. Let's assume our batch size is 6,the sequence length is 60, and vocab size is 10000. Let's see how this looks below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j62K5SNmINhS",
        "colab_type": "code",
        "outputId": "7c5a86e2-cdd6-401a-c1e4-0faeb9f2f005",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "sample = torch.rand(64, 60, 10000)\n",
        "print(f'the size number is of: {sample.size()}')\n",
        "print(f'the total element number is of: {sample.numel()}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the size number is of: torch.Size([64, 60, 10000])\n",
            "the total element number is of: 38400000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Es3yTOVVJ9x4",
        "colab_type": "text"
      },
      "source": [
        "The first thing you will notice is the huge size in vocbulary, which is typical when using what's called **one-hot encodings**. There is also option to encode words and sentences into efficient **embeddings**. This ensure a more efficient representation as words can be represented to have semantic relationship.\n",
        "\n",
        "In such case, the dimensions reduced and they typically look like the following:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uyq0Gn6MINmm",
        "colab_type": "code",
        "outputId": "cd19845e-7fb1-487d-bbcf-fe1641cae641",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "sample_with_embeddings = torch.rand(64, 60, 100)\n",
        "print(f'the size number is of: {sample_with_embeddings.size()}')\n",
        "print(f'the total element number is of: {sample_with_embeddings.numel()}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the size number is of: torch.Size([64, 60, 100])\n",
            "the total element number is of: 384000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9GscH5HKWHD",
        "colab_type": "text"
      },
      "source": [
        "Note now that the 3rd dimension has been significantly reduced in dimensoin because we are using embeddings as input to represente sequences. This not only ensure efficiency in terms of meaning buy also the network will train more efficiently because the dimension are reduced."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_mbJmdVxKbJd",
        "colab_type": "text"
      },
      "source": [
        "#### **Tensor Transformation**\n",
        "Sometimes we need to **permute** the dimensions of the tensor. How do we do this in PyTorch? Please visit the PyTorch documentation to find out how to achieve a tranformation of the original size of the tensor. Hint: **A.permute()**. Try to permute the sample_with_embeddings above to be of the following dimenions instead: _{max_sequence_length * batch_size * vocab_size}_."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1bxJ0YZyLII3",
        "colab_type": "code",
        "outputId": "661940ff-b10c-45a9-821d-4285f61364da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "source": [
        "sample_with_embeddings[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.4167, 0.5443, 0.7273,  ..., 0.4806, 0.2747, 0.8416],\n",
              "        [0.2645, 0.9291, 0.8072,  ..., 0.9039, 0.0592, 0.3381],\n",
              "        [0.6887, 0.3476, 0.1404,  ..., 0.0358, 0.2000, 0.9399],\n",
              "        ...,\n",
              "        [0.3001, 0.7335, 0.3546,  ..., 0.8808, 0.8815, 0.4774],\n",
              "        [0.6429, 0.6869, 0.9452,  ..., 0.5972, 0.1473, 0.8735],\n",
              "        [0.9811, 0.7691, 0.3593,  ..., 0.2998, 0.5371, 0.1857]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJCbluIGINpd",
        "colab_type": "code",
        "outputId": "ded62b44-e157-40c9-b884-677687dc2a21",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "sample_with_embeddings[0].size()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([60, 100])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9HiLEK3dMF__",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6q0lPYXXMGk-",
        "colab_type": "text"
      },
      "source": [
        "## **Linear Transformation**\n",
        "A fundamental operation of training a neural network is **affine mapping** or **linear transformations**, which is simply a tranformation of a tensor given some function. PyTorch already packages various linear transformations, so we don't need to manually implement them.\n",
        "\n",
        "Let's look at the example below. We wish to output the hidden representation using randomly initialized weight and biases. In other words, we wish to compute the following:\n",
        "\n",
        "**y = Wx + b**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "952M2sh0KPRT",
        "colab_type": "code",
        "outputId": "18f3bda3-f608-4219-c741-090c58216557",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "# using Linear unit in PyTorch\n",
        "\n",
        "sample_x = torch.rand(64, 60, 100)\n",
        "\n",
        "fc = nn.Linear(100, 50)               # Wx + b     you only need provide dimensions \n",
        "\n",
        "# chaining happening automatically\n",
        "out = fc(sample_x)\n",
        "\n",
        "print(out.size())\n",
        "print(sample_x)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([64, 60, 50])\n",
            "tensor([[[3.2660e-01, 2.7459e-01, 8.0994e-02,  ..., 2.8569e-01,\n",
            "          2.0536e-01, 6.6281e-01],\n",
            "         [3.9845e-01, 8.4902e-01, 5.3731e-01,  ..., 7.4523e-01,\n",
            "          1.9759e-01, 3.2963e-01],\n",
            "         [2.8975e-01, 2.0450e-01, 2.6999e-01,  ..., 2.7248e-01,\n",
            "          6.2096e-01, 8.6310e-01],\n",
            "         ...,\n",
            "         [7.3211e-01, 4.3403e-01, 4.0419e-01,  ..., 1.3821e-01,\n",
            "          3.1642e-01, 1.9150e-01],\n",
            "         [4.4580e-01, 1.2637e-01, 1.7299e-01,  ..., 8.6654e-01,\n",
            "          7.8285e-01, 1.0592e-01],\n",
            "         [6.4025e-01, 8.7210e-01, 7.7999e-01,  ..., 2.7700e-01,\n",
            "          2.3263e-01, 4.2536e-01]],\n",
            "\n",
            "        [[4.3663e-01, 5.4482e-01, 5.7934e-02,  ..., 5.2575e-01,\n",
            "          6.4258e-01, 5.8679e-01],\n",
            "         [4.0286e-01, 5.5827e-01, 7.2883e-01,  ..., 2.7344e-01,\n",
            "          4.2456e-01, 2.4720e-01],\n",
            "         [2.8393e-01, 7.2880e-01, 6.7231e-01,  ..., 3.6974e-02,\n",
            "          1.6632e-01, 3.7125e-01],\n",
            "         ...,\n",
            "         [2.6654e-01, 3.8918e-01, 3.5493e-01,  ..., 6.7008e-01,\n",
            "          7.7786e-01, 2.6696e-01],\n",
            "         [2.9565e-01, 8.8619e-01, 6.7800e-01,  ..., 8.1840e-01,\n",
            "          7.1676e-01, 4.6338e-01],\n",
            "         [4.8385e-01, 4.1490e-01, 7.9504e-01,  ..., 9.8780e-01,\n",
            "          8.3646e-01, 5.6485e-01]],\n",
            "\n",
            "        [[4.7987e-01, 2.0319e-01, 8.8828e-01,  ..., 1.5877e-01,\n",
            "          1.8834e-01, 1.2143e-01],\n",
            "         [9.8431e-01, 5.0890e-02, 9.2091e-01,  ..., 2.4161e-01,\n",
            "          9.5355e-01, 6.9260e-01],\n",
            "         [9.7962e-01, 4.0227e-01, 1.4365e-01,  ..., 8.1472e-01,\n",
            "          3.2517e-01, 4.0285e-01],\n",
            "         ...,\n",
            "         [6.4005e-01, 1.7480e-01, 4.8567e-01,  ..., 2.7318e-01,\n",
            "          2.3464e-01, 6.0622e-03],\n",
            "         [9.8179e-03, 5.4958e-01, 8.3630e-03,  ..., 5.0792e-01,\n",
            "          4.2834e-01, 5.0433e-01],\n",
            "         [1.4081e-02, 7.1097e-01, 9.1555e-01,  ..., 1.5991e-01,\n",
            "          9.3244e-02, 3.4074e-02]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[7.4450e-01, 1.0909e-01, 2.1231e-01,  ..., 2.6404e-01,\n",
            "          9.3804e-01, 8.3922e-01],\n",
            "         [6.8340e-01, 9.8569e-01, 9.3092e-01,  ..., 7.5681e-01,\n",
            "          7.6832e-01, 4.4286e-01],\n",
            "         [6.1661e-01, 6.6889e-01, 3.5460e-01,  ..., 8.1286e-01,\n",
            "          4.7134e-01, 6.9213e-02],\n",
            "         ...,\n",
            "         [4.8144e-01, 7.3385e-01, 9.6588e-01,  ..., 3.8774e-01,\n",
            "          1.0842e-02, 5.6841e-01],\n",
            "         [7.3963e-01, 4.3820e-01, 4.2313e-01,  ..., 5.2656e-01,\n",
            "          6.8415e-01, 7.6589e-01],\n",
            "         [1.9827e-01, 4.8786e-01, 3.5964e-01,  ..., 9.8334e-01,\n",
            "          3.2403e-01, 7.7475e-01]],\n",
            "\n",
            "        [[6.4079e-01, 3.5086e-01, 4.3594e-01,  ..., 4.9330e-01,\n",
            "          5.2024e-02, 7.6208e-01],\n",
            "         [9.7359e-01, 8.2376e-01, 1.4895e-01,  ..., 3.1780e-01,\n",
            "          4.5465e-01, 2.6424e-01],\n",
            "         [4.0103e-01, 3.3286e-01, 7.3384e-01,  ..., 9.7472e-02,\n",
            "          7.1215e-01, 1.0077e-01],\n",
            "         ...,\n",
            "         [6.2352e-01, 7.5157e-01, 3.1267e-01,  ..., 3.6763e-01,\n",
            "          9.7718e-01, 4.2024e-01],\n",
            "         [1.5154e-01, 3.6953e-01, 8.0066e-01,  ..., 7.0192e-02,\n",
            "          7.0428e-01, 4.6118e-01],\n",
            "         [1.2109e-01, 5.1306e-01, 8.6369e-02,  ..., 8.6696e-03,\n",
            "          8.1593e-01, 3.1289e-01]],\n",
            "\n",
            "        [[2.4647e-01, 9.0342e-01, 4.1671e-01,  ..., 3.0707e-01,\n",
            "          1.0145e-01, 1.6472e-01],\n",
            "         [8.7363e-01, 6.0279e-01, 1.6069e-04,  ..., 4.3321e-01,\n",
            "          9.8796e-01, 4.0956e-01],\n",
            "         [8.3361e-01, 3.6086e-01, 5.8062e-02,  ..., 3.9745e-01,\n",
            "          6.9054e-01, 8.0096e-01],\n",
            "         ...,\n",
            "         [2.0674e-01, 3.3607e-01, 1.4382e-01,  ..., 7.4674e-01,\n",
            "          1.2382e-01, 9.1456e-01],\n",
            "         [1.9758e-01, 5.1515e-01, 1.2888e-01,  ..., 1.0784e-01,\n",
            "          4.9300e-01, 4.2454e-01],\n",
            "         [2.6785e-02, 2.7620e-02, 8.2500e-01,  ..., 5.8530e-01,\n",
            "          7.3880e-01, 1.6849e-01]]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cXLypcHMM2hi",
        "colab_type": "text"
      },
      "source": [
        "## **Non-linear Transformation**\n",
        "We can then apply a non-linear transformation using the results of the previous linear transformation, computed as follows:\n",
        "\n",
        "**h = sigmiod(Wx + b)**\n",
        "\n",
        "Sigmoid activation function in our example below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ChulzuCsKPWi",
        "colab_type": "code",
        "outputId": "a3100fe5-af9e-4ad3-a6ae-bced14e5c329",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 906
        }
      },
      "source": [
        "sample_x = torch.rand(64, 60, 100)\n",
        "\n",
        "fc = nn.Linear(100, 50)         # the Linear class did everything in background such as weights innitialization\n",
        "sig = nn.Sigmoid()\n",
        "\n",
        "out = fc(sample_x)\n",
        "out = sig(out)                  # [0, 1]\n",
        "\n",
        "print(out.size())\n",
        "print(sample_x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([64, 60, 50])\n",
            "tensor([[[0.8327, 0.4580, 0.8580,  ..., 0.0284, 0.3508, 0.4379],\n",
            "         [0.4855, 0.5231, 0.9947,  ..., 0.0727, 0.9151, 0.2560],\n",
            "         [0.7236, 0.3229, 0.3063,  ..., 0.7087, 0.0864, 0.0976],\n",
            "         ...,\n",
            "         [0.4146, 0.5652, 0.4103,  ..., 0.5533, 0.5456, 0.4220],\n",
            "         [0.9939, 0.2359, 0.6844,  ..., 0.6125, 0.5642, 0.7184],\n",
            "         [0.4461, 0.5078, 0.2558,  ..., 0.6217, 0.9633, 0.5419]],\n",
            "\n",
            "        [[0.3198, 0.4743, 0.1305,  ..., 0.5555, 0.9426, 0.4458],\n",
            "         [0.6244, 0.2177, 0.8523,  ..., 0.5752, 0.3186, 0.6287],\n",
            "         [0.7769, 0.7241, 0.5836,  ..., 0.5176, 0.2847, 0.3039],\n",
            "         ...,\n",
            "         [0.6459, 0.2224, 0.0854,  ..., 0.3090, 0.1527, 0.1926],\n",
            "         [0.9144, 0.8688, 0.3167,  ..., 0.9928, 0.2339, 0.4209],\n",
            "         [0.5101, 0.6048, 0.5862,  ..., 0.7638, 0.1307, 0.6792]],\n",
            "\n",
            "        [[0.1397, 0.5883, 0.5324,  ..., 0.5727, 0.5222, 0.0061],\n",
            "         [0.4897, 0.2426, 0.5369,  ..., 0.1028, 0.9214, 0.2836],\n",
            "         [0.0210, 0.1467, 0.5592,  ..., 0.0239, 0.2136, 0.1456],\n",
            "         ...,\n",
            "         [0.1846, 0.3303, 0.3802,  ..., 0.0482, 0.9090, 0.8358],\n",
            "         [0.4062, 0.2603, 0.9630,  ..., 0.9777, 0.0664, 0.2533],\n",
            "         [0.6366, 0.8013, 0.2916,  ..., 0.3073, 0.5922, 0.1190]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[0.2853, 0.1333, 0.9818,  ..., 0.9275, 0.5187, 0.2716],\n",
            "         [0.2776, 0.4007, 0.7491,  ..., 0.6179, 0.2666, 0.5654],\n",
            "         [0.6646, 0.4227, 0.3174,  ..., 0.9266, 0.9011, 0.2027],\n",
            "         ...,\n",
            "         [0.3577, 0.2315, 0.0488,  ..., 0.8718, 0.1522, 0.1301],\n",
            "         [0.2406, 0.7956, 0.7687,  ..., 0.0579, 0.9373, 0.9879],\n",
            "         [0.6802, 0.8404, 0.6734,  ..., 0.7199, 0.6965, 0.7938]],\n",
            "\n",
            "        [[0.0311, 0.0792, 0.0512,  ..., 0.2798, 0.0571, 0.8706],\n",
            "         [0.9265, 0.9810, 0.3159,  ..., 0.3232, 0.2215, 0.6650],\n",
            "         [0.4642, 0.9471, 0.8069,  ..., 0.2989, 0.7972, 0.9231],\n",
            "         ...,\n",
            "         [0.4365, 0.1663, 0.6858,  ..., 0.7606, 0.6022, 0.3437],\n",
            "         [0.5764, 0.3129, 0.4447,  ..., 0.8552, 0.9752, 0.6311],\n",
            "         [0.5343, 0.1573, 0.5991,  ..., 0.4633, 0.7316, 0.1274]],\n",
            "\n",
            "        [[0.0870, 0.2349, 0.5787,  ..., 0.5442, 0.2367, 0.2159],\n",
            "         [0.1807, 0.7790, 0.2581,  ..., 0.5392, 0.3572, 0.0535],\n",
            "         [0.3535, 0.7708, 0.3679,  ..., 0.2275, 0.4281, 0.8454],\n",
            "         ...,\n",
            "         [0.9984, 0.5922, 0.1241,  ..., 0.8437, 0.1174, 0.8082],\n",
            "         [0.8236, 0.3970, 0.2717,  ..., 0.9561, 0.8561, 0.3398],\n",
            "         [0.4891, 0.6390, 0.5967,  ..., 0.0429, 0.4240, 0.8116]]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "znK-f9AGOIeS",
        "colab_type": "text"
      },
      "source": [
        "There are other popular non-linear transformation or activiation functions available for use such as **RelU** and **tanh**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J79L1IhjNxj7",
        "colab_type": "text"
      },
      "source": [
        "## **Softmax Classifier**\n",
        "This component of the neural network is called the **classifier**, which is usually in charge of making the final prediction via a normalized representation of the output layer. From the equation below you can see that to get this output we just need to apply a **softmax** function. The values returned will be in the range (0, 1) and sum to 1.\n",
        "\n",
        "**output = softmax(x)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BflMCa7gKPZN",
        "colab_type": "code",
        "outputId": "25e5b328-07b6-4c95-b2ec-5f2030f7b211",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "m = nn.Softmax(dim=1)\n",
        "x = torch.randn(4, 5)\n",
        "out = m(x)\n",
        "print(out)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.3248, 0.0938, 0.2058, 0.3047, 0.0710],\n",
            "        [0.1008, 0.0570, 0.3523, 0.1582, 0.3316],\n",
            "        [0.1321, 0.5767, 0.0290, 0.0691, 0.1931],\n",
            "        [0.1899, 0.5192, 0.1439, 0.0254, 0.1217]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1r6_QYwOcNk",
        "colab_type": "text"
      },
      "source": [
        "#### **Chaining Linear Layers**\n",
        "Go ahead and try to chain a few linear transformations, make it deep if you like. Revise the previous notebook to help you build a chain of operations.\n",
        "\n",
        "Feel free to explore the PyTorch documentation to familiarize yourself with more of the basic linear and non-linear transformations. In addition, try to change the size of the Linear layers and combining a series of them."
      ]
    }
  ]
}